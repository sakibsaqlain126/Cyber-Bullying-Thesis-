{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73567446",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-04T16:34:23.179247Z",
     "iopub.status.busy": "2025-12-04T16:34:23.178970Z",
     "iopub.status.idle": "2025-12-04T16:34:56.546638Z",
     "shell.execute_reply": "2025-12-04T16:34:56.545547Z"
    },
    "papermill": {
     "duration": 33.372082,
     "end_time": "2025-12-04T16:34:56.548014",
     "exception": false,
     "start_time": "2025-12-04T16:34:23.175932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Downloading NLTK stopwords...\n",
      "üáßüá© Bengali Hate Speech Detection Pipeline (Minimal)\n",
      "üì• Loading Bengali hate speech dataset...\n",
      "üìä Dataset shape: (30000, 3)\n",
      "üìã Columns: ['sentence', 'hate', 'category']\n",
      "‚úÖ Shape after dropping missing values: (30000, 3)\n",
      "üî¢ Encoding labels...\n",
      "üìã Label mapping: {0: 0, 1: 1}\n",
      "‚úÖ Shape after cleaning: (29902, 5)\n",
      "‚öñÔ∏è Applying oversampling to balance classes...\n",
      "‚úÖ Final dataset shape: (39820, 5)\n",
      "üî§ Extracting TF-IDF features...\n",
      "Train samples: 31856, Test samples: 7964\n",
      "\n",
      "üöÄ Training Random Forest...\n",
      "‚úÖ Test Accuracy: 0.9461\n",
      "\n",
      "üßæ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      3982\n",
      "           1       0.94      0.95      0.95      3982\n",
      "\n",
      "    accuracy                           0.95      7964\n",
      "   macro avg       0.95      0.95      0.95      7964\n",
      "weighted avg       0.95      0.95      0.95      7964\n",
      "\n",
      "üî• ROC AUC Score: 0.9461\n",
      "\n",
      "üß™ Sample Predictions:\n",
      "‡¶è‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‚Üí 0\n",
      "‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ñ‡ßÅ‡¶¨ ‡¶¨‡¶æ‡¶ú‡ßá ‚Üí 0\n",
      "‡¶Ü‡¶ú‡¶ï‡ßá‡¶∞ ‡¶ñ‡ßá‡¶≤‡¶æ ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶õ‡¶ø‡¶≤ ‚Üí 0\n",
      "‚è± Total inference time: 0.0347s\n",
      "‚è± Average inference time per sample: 0.0116s\n",
      "\n",
      "üíæ All outputs saved in /kaggle/working/bengali_model_outputs\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Bengali Hate Speech Detection - Random Forest\n",
    "# Option A (Minimal + Kaggle Output + Inference Time)\n",
    "# =========================\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.utils import resample\n",
    "import joblib\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Setup\n",
    "# -----------------------------\n",
    "print(\"üì¶ Downloading NLTK stopwords...\")\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üáßüá© Bengali Hate Speech Detection Pipeline (Minimal)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load Dataset\n",
    "# -----------------------------\n",
    "print(\"üì• Loading Bengali hate speech dataset...\")\n",
    "df = pd.read_csv(\"/kaggle/input/bagla-hate-spech/Bengali hate speech .csv\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìã Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Handle missing values\n",
    "# -----------------------------\n",
    "df = df.dropna()\n",
    "print(f\"‚úÖ Shape after dropping missing values: {df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Identify text and target columns\n",
    "# -----------------------------\n",
    "text_column = 'sentence'\n",
    "target_column = 'hate'\n",
    "\n",
    "# -----------------------------\n",
    "# Label encoding\n",
    "# -----------------------------\n",
    "print(\"üî¢ Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df[target_column])\n",
    "print(\"üìã Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "# -----------------------------\n",
    "# Create output folder\n",
    "# -----------------------------\n",
    "output_dir = \"/kaggle/working/bengali_model_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "joblib.dump(label_encoder, f\"{output_dir}/label_encoder.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Clean Bengali text\n",
    "# -----------------------------\n",
    "def clean_bengali_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s‡ß¶-‡ßØ0-9]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text if len(text) >= 3 else \"\"\n",
    "\n",
    "df['clean_text'] = df[text_column].apply(clean_bengali_text)\n",
    "df = df[df['clean_text'] != \"\"]\n",
    "print(f\"‚úÖ Shape after cleaning: {df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Balance dataset (optional)\n",
    "# -----------------------------\n",
    "class_counts = df['encoded_label'].value_counts()\n",
    "if class_counts.max() / class_counts.min() > 1.5:\n",
    "    print(\"‚öñÔ∏è Applying oversampling to balance classes...\")\n",
    "    max_count = class_counts.max()\n",
    "    balanced_df = pd.DataFrame()\n",
    "    for label in df['encoded_label'].unique():\n",
    "        df_label = df[df['encoded_label'] == label]\n",
    "        upsampled = resample(df_label, replace=True, n_samples=max_count, random_state=42)\n",
    "        balanced_df = pd.concat([balanced_df, upsampled])\n",
    "    df = balanced_df.copy()\n",
    "print(f\"‚úÖ Final dataset shape: {df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# TF-IDF\n",
    "# -----------------------------\n",
    "print(\"üî§ Extracting TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    "    lowercase=False,\n",
    "    token_pattern=r'[\\u0980-\\u09FF]+'\n",
    ")\n",
    "X = tfidf.fit_transform(df['clean_text'])\n",
    "y = df['encoded_label']\n",
    "\n",
    "joblib.dump(tfidf, f\"{output_dir}/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train-test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Train Random Forest\n",
    "# -----------------------------\n",
    "print(\"\\nüöÄ Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, f\"{output_dir}/random_forest_model.pkl\")\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate model\n",
    "# -----------------------------\n",
    "y_pred = rf_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"\\nüßæ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "pd.DataFrame(clf_report).transpose().to_csv(f\"{output_dir}/classification_report.csv\", index=True)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"{output_dir}/confusion_matrix.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"üî• ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature importance\n",
    "# -----------------------------\n",
    "importances = rf_model.feature_importances_\n",
    "top_n = 30\n",
    "indices = np.argsort(importances)[::-1][:top_n]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Top 30 Feature Importances\")\n",
    "plt.bar(range(top_n), importances[indices], align='center')\n",
    "plt.xticks(range(top_n), [tfidf.get_feature_names_out()[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/feature_importances.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Sample inference + average inference time\n",
    "# -----------------------------\n",
    "samples = [\"‡¶è‡¶ü‡¶æ ‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞\", \"‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ñ‡ßÅ‡¶¨ ‡¶¨‡¶æ‡¶ú‡ßá\", \"‡¶Ü‡¶ú‡¶ï‡ßá‡¶∞ ‡¶ñ‡ßá‡¶≤‡¶æ ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶õ‡¶ø‡¶≤\"]\n",
    "vec_samples = tfidf.transform([clean_bengali_text(t) for t in samples])\n",
    "\n",
    "start_time = time.time()\n",
    "preds = rf_model.predict(vec_samples)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "avg_inference_time = inference_time / len(samples)\n",
    "print(\"\\nüß™ Sample Predictions:\")\n",
    "for text, p in zip(samples, preds):\n",
    "    print(f\"{text} ‚Üí {label_encoder.inverse_transform([p])[0]}\")\n",
    "\n",
    "print(f\"‚è± Total inference time: {inference_time:.4f}s\")\n",
    "print(f\"‚è± Average inference time per sample: {avg_inference_time:.4f}s\")\n",
    "\n",
    "# Save predictions and inference times\n",
    "pred_df = pd.DataFrame({'text': samples, 'predicted_label': [label_encoder.inverse_transform([p])[0] for p in preds]})\n",
    "pred_df.to_csv(f\"{output_dir}/sample_predictions.csv\", index=False)\n",
    "\n",
    "with open(f\"{output_dir}/inference_times.txt\", \"w\") as f:\n",
    "    f.write(f\"Total inference time: {inference_time:.4f}s\\n\")\n",
    "    f.write(f\"Average inference time per sample: {avg_inference_time:.4f}s\\n\")\n",
    "\n",
    "print(f\"\\nüíæ All outputs saved in {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7698287,
     "sourceId": 12219280,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.910906,
   "end_time": "2025-12-04T16:34:57.167477",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-04T16:34:19.256571",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
